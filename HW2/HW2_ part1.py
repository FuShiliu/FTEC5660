# -*- coding: utf-8 -*-
"""homework2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pEQ7KaHTRVsmDvoHg8NMRuXJO3Jr5avD

# Homework 2

# Set up

## Installing packages
"""

!pip install requests PyPDF2 gdown
!pip install 'markitdown[pdf]'
!pip install langchain_mcp_adapters langchain_google_genai langchain-openai

"""## Setup your API key

To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.


1.   Look for the key icon on the left panel of your colab.
2.   Under `Name`, create `VERTEX_API_KEY`.
3. Copy your key to `Value`.

If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.


"""

from google.colab import userdata
GEMINI_VERTEX_API_KEY = userdata.get('GEMINI_VERTEX_API_KEY')
# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')

"""# Download sample CVs

## Downloading sample_cv.pdf
The codes below download the sample CV
"""

import os
import gdown

folder_id = "1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D"
folder_url = f"https://drive.google.com/drive/folders/{folder_id}"

output_dir = "downloaded_cvs"
os.makedirs(output_dir, exist_ok=True)

gdown.download_folder(
    url=folder_url,
    output=output_dir,
    quiet=False,
    use_cookies=False
)

# =====================================================
#  Load and display all CV PDFs in order
# =====================================================
import os
from markitdown import MarkItDown

cv_dir = "downloaded_cvs"

# Initialize MarkItDown
md = MarkItDown(enable_plugins=False)

# Collect and sort PDFs numerically
pdf_files = sorted(
    [f for f in os.listdir(cv_dir) if f.lower().endswith(".pdf")],
    key=lambda x: int("".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1
)

all_cvs = []

for pdf_name in pdf_files:
    pdf_path = os.path.join(cv_dir, pdf_name)
    result = md.convert(pdf_path)

    all_cvs.append({
        "file": pdf_name,
        "text": result.text_content
    })

    print("=" * 80)
    print(f"ðŸ“„ {pdf_name}")
    print("=" * 80)
    print(result.text_content)
    print("\n\n")

"""# Connect to our MCP server

Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.

Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp.

## Check which tools that the MCP server provide
"""

import asyncio
import json
from langchain_mcp_adapters.client import MultiServerMCPClient

client = MultiServerMCPClient({
    "social_graph": {
        "transport": "http",
        "url": "https://ftec5660.ngrok.app/mcp",
        "headers": {"ngrok-skip-browser-warning": "true"}
    }
})

mcp_tools = await client.get_tools()
for tool in mcp_tools:
    print(tool.name)
    print(tool.description)
    print(tool.args)
    print("\n\n------------------------------------------------------\n\n")

"""## A simple agent using tools from the MCP server

"""

import os
import asyncio
from typing import List

from langchain_core.tools import tool
from langchain_core.messages import HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_mcp_adapters.client import MultiServerMCPClient

from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type
import os
os.environ["GEMINI_API_KEY"] = "AIzaSyDe-dxjBhg-aoUmYBD5FguLAIkkSgKV2GM"

# ---------------------------
# 1) Local tool
# ---------------------------
@tool
def say_hello(name: str) -> str:
    """Say hello to a person by name."""
    return f"Hello, {name}! ðŸ‘‹"


# ---------------------------
# 2) Load MCP tools + merge
# ---------------------------
async def load_tools() -> List:
    client = MultiServerMCPClient({
        "social_graph": {
            "transport": "http",
            "url": "https://ftec5660.ngrok.app/mcp",
            "headers": {"ngrok-skip-browser-warning": "true"},
        }
    })
    mcp_tools = await client.get_tools()
    return mcp_tools + [say_hello]


# ---------------------------
# 3) Gemini init (Developer API key)
# ---------------------------
def build_gemini_llm():
    gemini_api_key = os.getenv("GEMINI_API_KEY")  # å»ºè®®åœ¨ Colab Secret / env é‡Œè®¾ç½®è¿™ä¸ª
    if not gemini_api_key:
        raise ValueError("Missing GEMINI_API_KEY. Please set it in environment/Colab Secrets.")

    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=gemini_api_key,
        temperature=0,
    )


def is_limit_zero_quota_error(e: Exception) -> bool:
    msg = str(e)
    return ("RESOURCE_EXHAUSTED" in msg) and ("limit: 0" in msg)


# ---------------------------
# 4) Invoke with retry (only helps when you have non-zero quota)
# ---------------------------
@retry(
    wait=wait_exponential(multiplier=1, min=1, max=20),
    stop=stop_after_attempt(5),
    retry=retry_if_exception_type(Exception),
)
async def ainvoke_with_retry(llm_with_tools, messages):
    return await llm_with_tools.ainvoke(messages)


async def main():
    tools = await load_tools()

    llm = build_gemini_llm()
    llm_with_tools = llm.bind_tools(tools)

    query = "Say hello to Bao using tool, then search for someone named Alice on Facebook."
    messages = [HumanMessage(content=query)]

    try:
        resp = await ainvoke_with_retry(llm_with_tools, messages)
        print(resp)
    except Exception as e:
        # If quota is literally 0, retrying won't fix it â€” fail fast with a clear message.
        if is_limit_zero_quota_error(e):
            raise RuntimeError(
                "Gemini API quota is `limit: 0` for this project/model (gemini-2.0-flash). "
                "This cannot be solved by retry. You must enable billing / correct project "
                "or use a key from a project with non-zero quota."
            ) from e
        raise


# In Colab / Jupyter:
await main()

# This block provides you some tests to get faminilar with our MCP server

# # Test 1: Search Facebook users (exact match)
# await tools[0].ainvoke({'q': "Alex Chan", 'limit': 5})

# # Test 2: Search Facebook users (fuzzy match with typo)
# await tools[0].ainvoke({'q': "Alx Chn", 'limit': 5, 'fuzzy': True})

# # Test 3: Get Facebook profile
# await tools[1].ainvoke({'user_id': 123})

# # Test 4: Get Facebook mutual friends
# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})

# # Test 5: Search LinkedIn people (exact match)
# await tools[3].ainvoke({'q': "Python", 'location': "Hong Kong", 'limit': 5})

# # Test 6: Search LinkedIn people (fuzzy match with typo)
# await tools[3].ainvoke({'q': "Python", 'location': "Hong Kong", 'limit': 5, 'fuzzy': True})

# # Test 7: Get LinkedIn profile
# await tools[4].ainvoke({'person_id': 456})

# Test 8: Get LinkedIn interactions
await tools[5].ainvoke({'person_id': 456})

"""# Evaluation code

In the test phase, you will be given 5 CV files with fixed names:

    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf

Your system must process these CVs and output a list of 5 scores,
one score per CV, in the same order:

    scores = [s1, s2, s3, s4, s5]

Each score must be a float in the range [0, 1], representing the
reliability or confidence that the CV is valid (or meets the task criteria).

The ground-truth labels are binary:

    groundtruth = [0 or 1, ..., 0 or 1]

Each CV is evaluated independently using a threshold of 0.5:

- If score > 0.5 and groundtruth == 1 â†’ Full credit
- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit
- Otherwise â†’ No credit

In other words, 0.5 is the decision threshold.

- Each CV contributes equally.
- Final score = (number of correct decisions) / 5

"""

# =====================================================
#  Evaluation code
# =====================================================

def evaluate(scores, groundtruth, threshold=0.5):
    """
    scores: list of floats in [0, 1], length = 5
    groundtruth: list of ints (0 or 1), length = 5
    """
    assert len(scores) == 5
    assert len(groundtruth) == 5

    correct = 0
    decisions = []

    for s, gt in zip(scores, groundtruth):
        pred = 1 if s > threshold else 0
        decisions.append(pred)
        if pred == gt:
            correct += 1

    final_score = correct / len(scores)

    return {
        "decisions": decisions,
        "correct": correct,
        "total": len(scores),
        "final_score": final_score
    }

import re
import json
import math
from langchain_core.messages import HumanMessage

# --------- 1) å°å·¥å…·ï¼šæ–‡æœ¬ç›¸ä¼¼åº¦ ----------
def _norm(s: str) -> str:
    s = (s or "").strip().lower()
    s = re.sub(r"\s+", " ", s)
    return s

def _token_set(s: str) -> set:
    s = _norm(s)
    s = re.sub(r"[^a-z0-9\s\-]", " ", s)
    toks = [t for t in s.split() if len(t) >= 2]
    return set(toks)

def jaccard(a: str, b: str) -> float:
    A, B = _token_set(a), _token_set(b)
    if not A and not B:
        return 0.0
    return len(A & B) / max(1, len(A | B))

def clip01(x: float) -> float:
    return max(0.0, min(1.0, float(x)))

def find_tool(tools, contains: str):
    contains = contains.lower()
    for t in tools:
        if contains in t.name.lower():
            return t
    raise ValueError(f"Tool not found containing '{contains}'. Run Cell 12 to see tool names, then adjust the substring.")

# --------- 2) ç”¨ LLM ä»Ž CV æŠ½å–ç»“æž„åŒ–ä¿¡æ¯ ----------
EXTRACT_PROMPT = """Extract structured data from a resume/CV.
Return ONLY valid JSON (no markdown). Unknown -> null or [].

Schema:
{
  "name": string|null,
  "location": string|null,
  "education": [{"school": string|null, "degree": string|null}],
  "experience": [{"company": string|null, "title": string|null}],
  "skills": [string]
}

CV text:
"""

async def extract_cv_fields(llm, cv_text: str):
    msg = HumanMessage(content=EXTRACT_PROMPT + (cv_text or "")[:12000])
    out = await llm.ainvoke([msg])
    raw = out.content if hasattr(out, "content") else str(out)
    raw = raw.strip()
    m = re.search(r"\{.*\}", raw, flags=re.S)
    if m:
        raw = m.group(0)
    return json.loads(raw)

def flatten_profile_text(profile: dict) -> str:
    parts = []
    for k in ["name", "full_name", "headline", "location", "about", "summary"]:
        v = profile.get(k)
        if isinstance(v, str) and v.strip():
            parts.append(v.strip())
    for k in ["education", "experiences", "experience", "positions"]:
        v = profile.get(k)
        if isinstance(v, list):
            for it in v:
                if isinstance(it, dict):
                    parts.extend([str(x) for x in it.values() if isinstance(x, (str, int))])
    return " ".join(parts)

def score_overlap_list(cv_list, profile_text: str) -> float:
    if not cv_list:
        return 0.0
    pt = _norm(profile_text)
    base = 0
    hit = 0
    for s in cv_list:
        s2 = _norm(s)
        if not s2:
            continue
        base += 1
        if s2 in pt:
            hit += 1
    return 0.0 if base == 0 else hit / base

def score_one(cv: dict, li_profile: dict, li_profile_text: str, li_interactions, fb_profile) -> float:
    # 1) identity
    cv_name = cv.get("name") or ""
    cv_loc  = cv.get("location") or ""
    li_name = li_profile.get("name") or li_profile.get("full_name") or ""
    li_loc  = li_profile.get("location") or ""
    identity = clip01(0.75 * jaccard(cv_name, li_name) + 0.25 * jaccard(cv_loc, li_loc))

    # 2) experience / education / skills
    companies = [e.get("company") for e in (cv.get("experience") or []) if isinstance(e, dict) and e.get("company")]
    titles    = [e.get("title") for e in (cv.get("experience") or []) if isinstance(e, dict) and e.get("title")]
    schools   = [e.get("school") for e in (cv.get("education") or []) if isinstance(e, dict) and e.get("school")]
    degrees   = [e.get("degree") for e in (cv.get("education") or []) if isinstance(e, dict) and e.get("degree")]
    skills    = (cv.get("skills") or [])[:30]

    exp_s  = clip01(0.7 * score_overlap_list(companies, li_profile_text) + 0.3 * score_overlap_list(titles, li_profile_text))
    edu_s  = clip01(0.8 * score_overlap_list(schools, li_profile_text)   + 0.2 * score_overlap_list(degrees, li_profile_text))
    sk_s   = clip01(score_overlap_list(skills, li_profile_text))

    # 3) social presence (ç®€å•åŽ‹ç¼©æˆ 0~1)
    li_count = len(li_interactions) if isinstance(li_interactions, list) else 0
    li_social = 1.0 - math.exp(-li_count / 20.0) if li_count > 0 else 0.0
    fb_social = 0.5 if isinstance(fb_profile, dict) else 0.0
    social_s  = clip01(0.7 * li_social + 0.3 * fb_social)

    score = 0.40 * identity + 0.30 * exp_s + 0.10 * edu_s + 0.10 * sk_s + 0.10 * social_s
    if not (cv.get("name") or "").strip():
        score *= 0.7
    return clip01(score)

# --------- 3) ç”Ÿæˆ scores ----------
async def generate_scores_from_all_cvs(all_cvs):
    # A) MCP toolsï¼ˆç”¨ä½ å‰é¢ cell 14 çš„ load_toolsï¼‰
    tools = await load_tools()

    # B) è¿™é‡Œç”¨ substring æ‰¾å·¥å…·ã€‚è‹¥æŠ¥ Tool not foundï¼šå…ˆè·‘ Cell 12ï¼Œçœ‹çœŸå®žåå­—ï¼Œå†æ”¹ substring
    linkedin_search = find_tool(tools, "linkedin")               # e.g. search_linkedin_users
    linkedin_get_profile = find_tool(tools, "get_linkedin_profile")
    linkedin_get_interactions = find_tool(tools, "linkedin_interactions")

    facebook_search = find_tool(tools, "facebook")               # e.g. search_facebook_users
    facebook_get_profile = find_tool(tools, "get_facebook_profile")

    # C) LLM
    llm = build_gemini_llm()

    scores = []
    for item in all_cvs:
        cv_text = item["text"] or ""
        cv = await extract_cv_fields(llm, cv_text)

        name = cv.get("name") or ""
        location = cv.get("location") or ""

        # 1) LinkedIn search
        li_candidates = []
        try:
            li_res = await linkedin_search.ainvoke({"q": name, "location": location, "limit": 5, "fuzzy": True})
            li_candidates = li_res if isinstance(li_res, list) else (li_res.get("results") or li_res.get("people") or li_res.get("items") or [])
        except Exception:
            li_candidates = []

        # pick best candidate by name/location similarity
        best = None
        best_s = -1
        for it in li_candidates:
            s = 0.8 * jaccard(name, str(it.get("name") or it.get("full_name") or "")) + 0.2 * jaccard(location, str(it.get("location") or ""))
            if s > best_s:
                best, best_s = it, s

        li_profile = None
        li_profile_text = ""
        li_interactions = []

        if best:
            pid = best.get("person_id") or best.get("id")
            if pid is not None:
                try:
                    li_profile = await linkedin_get_profile.ainvoke({"person_id": pid})
                    if isinstance(li_profile, dict):
                        li_profile_text = flatten_profile_text(li_profile)
                except Exception:
                    li_profile = None
                try:
                    li_interactions = await linkedin_get_interactions.ainvoke({"person_id": pid})
                except Exception:
                    li_interactions = []

        # 2) Facebook (optional)
        fb_profile = None
        try:
            fb_res = await facebook_search.ainvoke({"q": name, "limit": 5, "fuzzy": True})
            fb_candidates = fb_res if isinstance(fb_res, list) else (fb_res.get("results") or [])
            best_fb = None
            best_fb_s = -1
            for it in fb_candidates:
                s = jaccard(name, str(it.get("name") or ""))
                if s > best_fb_s:
                    best_fb, best_fb_s = it, s
            if best_fb:
                uid = best_fb.get("user_id") or best_fb.get("id")
                if uid is not None:
                    fb_profile = await facebook_get_profile.ainvoke({"user_id": uid})
        except Exception:
            fb_profile = None

        # 3) score
        if not isinstance(li_profile, dict) or not li_profile_text.strip():
            # æ²¡æ‰¾åˆ° LinkedInï¼šä½Žåˆ†
            s = 0.15 + (0.10 if isinstance(fb_profile, dict) else 0.0)
            scores.append(clip01(s))
        else:
            scores.append(score_one(cv, li_profile, li_profile_text, li_interactions, fb_profile))

    return scores

scores = await generate_scores_from_all_cvs(all_cvs)
print("scores =", scores)

groundtruth = [1, 1, 1, 0, 0] # Do not modify
result = evaluate(scores, groundtruth)
print(result)